# Evidence Quality Reference

## Evidence Hierarchy

Strongest to weakest for intervention effects:

| Level | Design | Strengths | Weaknesses |
|-------|--------|-----------|------------|
| 1 | Systematic reviews/meta-analyses | Combines studies, reduces anomalies | Garbage in = garbage out |
| 2 | RCTs | Gold standard for causation | Expensive, may lack generalizability |
| 3 | Cohort | Temporal sequence, multiple outcomes | Susceptible to confounding |
| 4 | Case-control | Efficient for rare outcomes | Recall bias, can't calculate incidence |
| 5 | Cross-sectional | Quick, establishes prevalence | No temporal sequence |
| 6 | Case reports | Hypothesis-generating | No controls, high bias |
| 7 | Expert opinion | Synthesizes experience | Subjective, lowest level |

**Critical**: Higher design ≠ higher quality. A well-designed cohort beats a poor RCT.

## GRADE System

Rate evidence: **High → Moderate → Low → Very Low**

### Starting Point
- RCTs start at High
- Observational starts at Low

### Downgrade Factors (-1 or -2 each)

| Factor | When to Downgrade |
|--------|-------------------|
| Risk of bias | Inadequate randomization, blinding, allocation concealment |
| Inconsistency | I² > 50%, contradictory results across studies |
| Indirectness | Wrong population, intervention, comparator, or outcome |
| Imprecision | Wide CIs, small sample, few events |
| Publication bias | Funnel plot asymmetry, missing studies |

### Upgrade Factors (+1 or +2 each, observational only)

| Factor | When to Upgrade |
|--------|-----------------|
| Large effect | RR > 2 or < 0.5 with no confounding |
| Dose-response | Clear gradient relationship |
| Confounders | Would reduce effect, not inflate it |

## Validity Types

| Type | Question | Key Threats |
|------|----------|-------------|
| **Internal** | Can we trust the causal inference? | Selection, confounding, attrition, measurement bias |
| **External** | Do results generalize? | Non-representative sample, artificial setting |
| **Construct** | Do measures capture intended constructs? | Invalid instruments, proxy measures |
| **Statistical** | Are statistical inferences sound? | Low power, assumption violations, multiple comparisons |

## Critical Appraisal Tools

| Study Type | Tool |
|------------|------|
| RCTs | Cochrane Risk of Bias (ROB 2) |
| Observational | Newcastle-Ottawa Scale, ROBINS-I |
| Diagnostic | QUADAS-2 |
| Systematic reviews | AMSTAR-2 |
| All types | CASP Checklists |

## Convergence Assessment

Evidence is **stronger** when:
- Multiple independent replications
- Different research groups and settings
- Different methodologies converge
- Mechanistic and empirical evidence align

Evidence is **weaker** when:
- Single study or research group
- Contradictory findings
- Publication bias evident
- No replication attempts

## Bradford Hill Criteria (Causation)

| Criterion | Description |
|-----------|-------------|
| Strength | Large effect size |
| Consistency | Replicated across studies |
| Specificity | Specific cause → specific effect |
| Temporality | Cause precedes effect (essential) |
| Biological gradient | Dose-response |
| Plausibility | Fits existing knowledge |
| Coherence | Consistent with related evidence |
| Experiment | Experimental support |
| Analogy | Similar relationships exist |
